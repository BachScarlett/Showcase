---
title: "242 Final Project"
author: "Joanne Jiang, Peter Pan, Huidi Wang, Yuyang Zhao, Yiyaqi Zuo"
date: "12/9/2019"
output: pdf_document
---

## INTRODUCTION


```{r  LOAD LIBRARIES AND DATA}
library(tm)
library(SnowballC)
library(wordcloud)
library(MASS)
library(caTools)
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)

library(tm.plugin.webmining)
library(boot)
library(ggplot2) 
library(readr) 
library(RColorBrewer)
library(biclust)
library(cluster)
library(igraph)
library(fpc)

library(gridExtra)
library(cowplot)
library(reshape2)
library(scales)
library(ngram)

airline=read.csv('Airline-Sentiment-2-w-AA.csv',stringsAsFactors=FALSE)
```

## 1. UNDERSTANDING DATASET
```{r  1. UNDERSTANDING DATASET}
# 1. Global customers' sentiment histogram
overallSentiment = as.data.frame(table(airline$airline_sentiment))
colnames(overallSentiment) = c("Sentiment","Count")

histPlot1 = ggplot(overallSentiment) + aes(x=Sentiment, y=Count, fill=Sentiment) + scale_fill_manual(values=c("indianred1","deepskyblue","chartreuse3"))
histPlot1 = histPlot1 + geom_bar(stat="identity")
histPlot1

table(airline$airline_sentiment)

# 2. Customers' sentiment towards different Airlines histogram
airlineSentiment = as.data.frame(table(airline$airline,airline$airline_sentiment))
colnames(airlineSentiment) = c("Airline","Sentiment","Count")

colours = c("firebrick1","deepskyblue","chartreuse3")

histPlot2 = ggplot(airlineSentiment) + aes(x=Airline,y=Count,fill=Sentiment) + scale_fill_manual(values=c("indianred1","deepskyblue","chartreuse3"))
histPlot2 = histPlot2 + geom_bar(stat="identity") +theme(axis.text.x = element_text(angle = 20, hjust = 0.5, vjust = 0.5))
histPlot2

table(airline$airline,airline$airline_sentiment)

# 3. Customers' sentiment on specific weekdays histogram
daySentiment = as.data.frame(table(airline$day,airline$airline_sentiment))
colnames(daySentiment) = c("Day","Sentiment","Count")

colours = c("firebrick1","deepskyblue","chartreuse3")

histPlot3 = ggplot(daySentiment) + aes(x=Day,y=Count,fill=Sentiment) + scale_fill_manual(values=c("indianred1","deepskyblue","chartreuse3"))
histPlot3 = histPlot3 + geom_bar(stat="identity") +theme(axis.text.x = element_text(angle = 20, hjust = 0.5, vjust = 0.5))
histPlot3

table(airline$day,airline$airline_sentiment)

# 4. Negative reason
# Initial Global analysis
#str(airline)
table(airline$negativereason, airline$airline)

globalSentReasons = as.data.frame(table(airline$negativereason, airline$airline))
colnames(globalSentReasons) = c("Reason","Airline", "Freq")
#globalSentReasons

ggplot(globalSentReasons) + aes(y = Freq, x = Reason, group = Airline, colour = Airline) + coord_polar() + geom_point() + geom_path()


## TYRING TO CALCULATE PERCENTAGES
aggregate(Freq ~ Airline, globalSentReasons, sum)
globalSentReasons$TotalTwAirline = 0
globalSentReasons[1:11,4] = 2759
globalSentReasons[12:22,4] = 2222
globalSentReasons[23:33,4] = 2420
globalSentReasons[34:44,4] = 3822
globalSentReasons[45:55,4] = 2913
globalSentReasons[56:66,4] = 503
globalSentReasons$PercentOfTotal = (globalSentReasons[,3]/globalSentReasons[,4])*100

ggplot(globalSentReasons) + aes(y = PercentOfTotal, x = Reason, group = Airline, colour = Airline) + coord_polar() + geom_point() + geom_path() + labs(x = NULL)
#ggplot(globalSentReasons) + aes(y = PercentOfTotal, x = Reason, group = Airline, colour = Airline) + geom_hist() + geom_path() + labs(x = NULL)

# 5. Word count 
airline$word_count <- sapply(airline$text, function(x) length(unlist(strsplit(as.character(x),"\\W+"))))
word_count <- airline$word_count
hist(word_count,
     main='Tweets Word Count',
     xlab='word count',
     xlim=c(1,50),
     ylim=c(0,2000),
     breaks=20,
     col = 'deepskyblue',
     freq=TRUE)
```


## 2.Data PROCESSING 
## DATA PRE-PROCESSING PART II: DATA CLEANING + NLP
```{r }
#Add tweet weekdate as a new feature
airline$tweet_date=weekdays(as.Date(airline$tweet_created))
#factorize negative sentiment as 1, other sentiment as 0
airline$Negative = as.factor(as.numeric(airline$airline_sentiment=="negative"))
```

```{r NLP Processing}



```

## 3. BUILDING MODELS-Approach1: NLP Models

```{r  3. BUILDING MODELS}
tableAccuracy <- function(test, pred) {
  t = table(test, pred)
  a = sum(diag(t))/length(test)
  return(a)
}


# Load the data set
tweets0 = read.csv("tweets0.csv", stringsAsFactors=FALSE)
set.seed(123)

tweets0$Negative = as.factor(as.numeric(tweets0$airline_sentiment=="negative"))
tweets0$airline_sentiment <- NULL

#spl = sample.split(tweets0$Negative, SplitRatio = 0.7)

train.ids <- sample(nrow(tweets0), 0.95*nrow(tweets0))
TweetsTrain <- tweets0[train.ids,]
TweetsTest <- tweets0[-train.ids,]

# split training into real training and validation set
val1.ids <- sample(nrow(TweetsTrain), (10/95)*nrow(TweetsTrain))
val1 <- TweetsTrain[val1.ids,]
TweetsTrain <- TweetsTrain[-val1.ids,]


#TweetsTrain = tweets0 %>% filter(spl == TRUE)
#TweetsTest = tweets0 %>% filter(spl == FALSE)

#Base line Model
#use to find the accuracy of baseline model
table(TweetsTest$Negative)
(471)/(471+261)


# Cross-validated CART model
set.seed(3421)
train.cart = train(Negative ~ .,
                   data = TweetsTrain,
                   method = "rpart",
                   tuneGrid = data.frame(cp=seq(0, 0.2, 0.002)),
                   trControl = trainControl(method="cv", number=10))
train.cart
train.cart$results

ggplot(train.cart$results, aes(x = cp, y = Accuracy)) + 
  geom_point(size = 2) + 
  geom_line() + 
  ylab("CV Accuracy") + 
  theme_bw() + 
  theme(axis.title=element_text(size=18), axis.text=element_text(size=18))

mod.cart = train.cart$finalModel
prp(mod.cart)

predict.cart = predict(mod.cart, newdata = TweetsTest, type = "class") # why no model.matrix? 
table(TweetsTest$Negative, predict.cart)
tableAccuracy(TweetsTest$Negative, predict.cart)


# Cross validated RF
# WARNING: this took me approx. 24 hour to run
set.seed(311)
train.rf = train(Negative ~ .,
                 data = TweetsTrain,
                 method = "rf",
                 tuneGrid = data.frame(mtry = 1:120),
                 trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE))
train.rf
train.rf$results

ggplot(train.rf$results, aes(x = mtry, y = Accuracy)) + geom_point(size = 2) + geom_line() + 
  ylab("CV Accuracy") + theme_bw() + 
  theme(axis.title=element_text(size=18), axis.text=element_text(size=18))

mod.rf = train.rf$finalModel
importance(mod.rf)
predict.rf = predict(mod.rf, newdata = TweetsTest)
table(TweetsTest$Negative, predict.rf)
tableAccuracy(TweetsTest$Negative, predict.rf)

# Logistic Regression

TweetLog = glm(Negative ~ ., data = TweetsTrain, family = "binomial")
PredictLog = predict(TweetLog, newdata = TweetsTest, type = "response")
# You may see a warning message - suspicious, but we will just ignore this

summary(TweetLog)
table(TweetsTest$Negative, PredictLog > 0.5)
tableAccuracy(TweetsTest$Negative, PredictLog > 0.5)


# Boosting
tGrid = expand.grid(n.trees = (1:100)*50, interaction.depth = c(1,2,4,6,8,10,12,14,16),
                    shrinkage = 0.01, n.minobsinnode = 10)

set.seed(232)
# WARNING: this took me approx. 8 hour to run
train.boost <- train(Negative ~ .,
                     data = TweetsTrain,
                     method = "gbm",
                     tuneGrid = tGrid,
                     trControl = trainControl(method="cv", number=5, verboseIter = TRUE),
                     metric = "Accuracy",
                     distribution = "bernoulli")
train.boost
train.boost$results

ggplot(train.boost$results, aes(x = n.trees, y = Accuracy, colour = as.factor(interaction.depth))) + geom_line() + 
  ylab("CV Accuracy") + theme_bw() + theme(axis.title=element_text(size=18), axis.text=element_text(size=18)) + 
  scale_color_discrete(name = "interaction.depth")

mod.boost = train.boost$finalModel
TweetsTest.mm = as.data.frame(model.matrix(Negative ~ . +0, data = TweetsTest))
predict.boost = predict(mod.boost, newdata = TweetsTest.mm, n.trees = 4100, type = "response")
table(TweetsTest$Negative, predict.boost < 0.5) # for some reason the probabilities are flipped in gbm
tableAccuracy(TweetsTest$Negative, predict.boost < 0.5)


```

## 3. BUILDING MODELS- Approach 2: Logistic Regression 
```{r}
library(gbm)

### Model2- Logistic Regression

model2_df<-airline[,c("Negative", "airline","tweet_date")]
df_Train <- model2_df[train.ids,]
df_Test <- model2_df[-train.ids,]
df_val1 <- df_Train[val1.ids,]
df_Train <- df_Train[-val1.ids,]


mod2Log = glm(Negative ~ ., data = df_Train, family = "binomial")
Predict_mod2Log = predict(mod2Log, newdata = df_Test, type = "response")
summary(Predict_mod2Log)
table(df_Test$Negative, Predict_mod2Log > 0.5)
tableAccuracy(df_Test$Negative, Predict_mod2Log > 0.5)
summary(mod2Log)
```

## 3. BUILDING MODELS- Blending Model: Approach1+Approach2
```{r}
###Blending: RF+BOOSTING+LOGISTIC

#Blending Prediction
set.seed(1000)
val.predict.rf=predict(mod.rf, newdata = val1)
val.predict.tweetlog=predict(mod.log, newdata = val1, type = "response")
val.predict.cart=predict(mod.cart, newdata = val1, type = "class")
TweetsVal.mm = as.data.frame(model.matrix(Negative ~ . +0, data = val1))
val.predict.boost=predict(mod.boost, newdata = TweetsVal.mm, n.trees = 3950, type = "response")
val.predict.log=predict(mod2Log, newdata = df_val1, type = "response")

# Build validation set data frame
val.blending_df = data.frame(Negative = (val1$Negative), 
                             log_preds = val.predict.log, 
                             rf_preds = (val.predict.rf)
                             #tweetlog_preds=val.predict.tweetlog,
                             #cart_preds=(val.predict.cart),
                             #boost_preds=val.predict.boost
                             )

# Train blended model
blend.mod =glm(Negative ~ . -1, data = val.blending_df, family = "binomial")
summary(blend.mod)


# Get predictions on test set
set.seed(1000)
test.predict.rf=predict(mod.rf, newdata = TweetsTest)
test.predict.tweetlog=predict(mod.log, newdata = TweetsTest, type = "response")
test.predict.cart=predict(mod.cart, newdata = TweetsTest, type = "class")
test.predict.boost=predict(mod.boost, newdata = TweetsTest.mm, n.trees = 3950, type = "response")
test.predict.log=predict(mod2Log, newdata = df_Test, type = "response")



test.blending_df = data.frame(Negative = (df_Test$Negative), 
                              log_preds = test.predict.log, 
                              rf_preds = (test.predict.rf)
                              #tweetlog_preds=test.predict.tweetlog,
                              #cart_preds=(test.predict.cart),
                              #boost_preds=test.predict.boost
)

test.preds.blend <- predict(blend.mod, newdata = test.blending_df,type = "response")

table(df_Test$Negative, test.preds.blend > 0.5)
tableAccuracy(df_Test$Negative, test.preds.blend > 0.5)
```

## 4. MODEL VALIDATION
```{r  4. MODEL VALIDATION}

### Data Validation: Bootstrap
#Best Final Model: Blending

tableAccuracy <- function(label, pred) {
  t = table(label, pred)
  a = sum(diag(t))/length(label)
  return(a)
}

tableTPR <- function(label, pred) {
  t = table(label, pred)
  return(t[2,2]/(t[2,1] + t[2,2]))
}

tableFPR <- function(label, pred) {
  t = table(label, pred)
  return(t[1,2]/(t[1,1] + t[1,2]))
}

boot_accuracy <- function(data, index) {
  labels <- data$label[index]
  predictions <- data$prediction[index]
  return(tableAccuracy(labels, predictions))
}

boot_tpr <- function(data, index) {
  labels <- data$label[index]
  predictions <- data$prediction[index]
  return(tableTPR(labels, predictions))
}

boot_fpr <- function(data, index) {
  labels <- data$label[index]
  predictions <- data$prediction[index]
  return(tableFPR(labels, predictions))
}

boot_all_metrics <- function(data, index) {
  acc = boot_accuracy(data, index)
  tpr = boot_tpr(data, index)
  fpr = boot_fpr(data, index)
  return(c(acc, tpr, fpr))
}

# Finalmodel
library(boot)
big_B=10000
blending_df = data.frame(labels = df_Test$Negative, predictions = test.preds.blend > 0.5)
set.seed(432)
Boost_boot = boot(blending_df, boot_all_metrics, R = big_B)
Boost_boot


boot.ci(Boost_boot, index = 1, type = "basic")  #CI for Accuracy of Boosting
boot.ci(Boost_boot, index = 2, type = "basic")  #CI for tpr of Boosting
boot.ci(Boost_boot, index = 3, type = "basic")  #CI for fpr of Boosting



```



## CONCLUSION


